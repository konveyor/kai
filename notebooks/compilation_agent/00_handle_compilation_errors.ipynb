{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Java Compilation Errors\n",
    "\n",
    "Explore how we would want to accept compilation errors, and how we would want the agent to get the updates that need to be made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install local kai package in the current Jupyter kernel\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install -e ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Base Agent type and an specific Compilation Agent Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Protocol, runtime_checkable\n",
    "from dataclasses import dataclass\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage\n",
    "from jinja2 import Template\n",
    "\n",
    "@dataclass\n",
    "class TaskRequest:\n",
    "    \"\"\"(Experimental Task Request)\n",
    "\n",
    "    A simple TaskRequest to just get the TaskAgent Protocal figured out.\n",
    "    \"\"\"\n",
    "\n",
    "    type_of_chat: str = None\n",
    "    compile_errors: List[str] = None\n",
    "    file_path: str = None\n",
    "\n",
    "@runtime_checkable\n",
    "class TaskAgent(Protocol):\n",
    "    \"\"\"A protocol for Task Agents to be used with the tasking system in Kai\n",
    "\n",
    "    An agent is responsible for doing a concreate piece of fixing of a java client\n",
    "    by using one or more LLM prompts and chats.\n",
    "    \"\"\"\n",
    "\n",
    "    def accepts(self,task_request: TaskRequest) -> bool:\n",
    "        \"\"\"Does this agent Accept the task\n",
    "\n",
    "        Args:\n",
    "            task_request (TaskRequest): the type of task and task information.\n",
    "        \"\"\" \n",
    "\n",
    "    async def run(self, task_request: TaskRequest) -> dict[str, any]:\n",
    "        \"\"\"Run the agent for the given TaskRequest\n",
    "        \"\"\"\n",
    "\n",
    "class CompilationErrorAgent(TaskAgent):\n",
    "    \"\"\"An agent responsible for dealing with compilation errors.\n",
    "    \"\"\"\n",
    "\n",
    "    system_message=SystemMessage(content=\"\"\"\n",
    "    I will give you compiler errors and the offending line of code, and you will need to use the file to determine how to fix them. You should only use compiler errors to determine what to fix.\n",
    "\n",
    "    Make sure that the references to any changed types are kept.\n",
    "\n",
    "    You must reason through the required changes and rewrite the Java file to make it compile. \n",
    "\n",
    "    You will then provide an step-by-step explaination of the changes required tso that someone could recreate it in a similar situation. \n",
    "    \"\"\")\n",
    "\n",
    "    chat_message_template=Template(\"\"\"\n",
    "    [INST]\n",
    "    ## Compile Errors\n",
    "    {{compile_errors}}\n",
    "\n",
    "    ## Input File\n",
    "    {{src_file_contents}}\n",
    "\n",
    "\n",
    "    # Ouput Instructions \n",
    "    Structure your output in Markdown format such as:\n",
    "\n",
    "    ## Updated Java File\n",
    "    Rewrite the java file here\n",
    "\n",
    "    ## Reasoning \n",
    "    Write the step by step reasoning in this markdown section. If you are unsure of a step or reasoning, clearly state you are unsure and why. \n",
    "\n",
    "    ## Addition Infomation (optional)\n",
    "    If you have additional details or steps that need to be perfomed, put it here. Say I have completed the changes when you are done explaining the reasoning[/INST]\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            name: str,\n",
    "            llm: BaseChatModel,\n",
    "    ):\n",
    "        \"\"\"docs\"\"\"\n",
    "        self.name = name\n",
    "        self.__llm = llm\n",
    "    \n",
    "    def accepts(self, task_request: TaskRequest) -> bool:\n",
    "        if task_request.type_of_chat == \"compilation\":\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    async def run(self, task_requst: TaskRequest) -> BaseMessage:\n",
    "        with open(task_requst.file_path) as f: src_file_contents= f.read()\n",
    "\n",
    "        compile_errors = \"\"\n",
    "        for c in task_requst.compile_errors:\n",
    "            compile_errors = \"\\n\".join([compile_errors, c])\n",
    "\n",
    "        content = self.chat_message_template.render(\n",
    "            src_file_contents=src_file_contents,\n",
    "            compile_errors=compile_errors)\n",
    "\n",
    "        aimessage = await self.__llm.ainvoke([self.system_message, HumanMessage(content=content)])\n",
    "        return aimessage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Prompt via a task.\n",
    "\n",
    "Create the Agent and then create the task_request to get the result of the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for the type of a field has changed for a given file\n",
    "\n",
    "This will test that field change, gets the correct output (updating the getter and setter to the new Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kai.service.llm_interfacing.model_provider import ModelProvider\n",
    "from kai.models.kai_config import KaiConfig\n",
    "import os\n",
    "\n",
    "config = KaiConfig.model_validate_filepath(\"../../kai/config.toml\")\n",
    "modelProvider = ModelProvider(config.models)\n",
    "agent = CompilationErrorAgent(\"java_compilation_error\", modelProvider.llm)\n",
    "\n",
    "task_request = TaskRequest(type_of_chat=\"CompilationError\", \n",
    "                           compile_errors=[\"Line of code: return itemId;\\nError: incompatible types: java.util.UUID cannot be converted to java.lang.String\",\n",
    "                                           \"Line of code: this.itemId = itemId;\\nError: incompatible types: java.lang.String cannot be converted to java.util.UUID\"],\n",
    "                            file_path=\"./testing_field_type_change_errors/InventoryEntity.java\")\n",
    "\n",
    "o = await agent.run(task_requst=task_request)\n",
    "\n",
    "print(o.content)\n",
    "\n",
    "if \"public UUID getItemId()\" in o.content:\n",
    "    print(\"Succesfull\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
