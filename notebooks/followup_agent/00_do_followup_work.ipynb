{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent to take follow up actions after analysis issue fix\n",
    "\n",
    "This is an agent that uses \"Additional Information\" from fix generation agent to make further changes.\n",
    "\n",
    "For faster prototyping, we use LangGraph for implementing this.\n",
    "\n",
    "We create a simple network of agents - FixGenerationAgent, FileOperationsAgent. \n",
    "\n",
    "The _FixGenerationAgent_ is the same as what we use today to fix analyzer issues. _FileOperationsAgent_ is a new agent we introduce that takes follow up actions. The follow up actions include updating another file, removing a file, or creating a new file. For each operation, we have a tool defined.\n",
    "\n",
    "![Diagram](./screenshots/Tool.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Generation Agent\n",
    "\n",
    "This is same as the existing agent we use to fix analysis issues.\n",
    "\n",
    "We are using a few hardcoded examples of analysis issues to generate fixes.\n",
    "\n",
    "Before proceeding, make sure you are using Kai venv to run cells in this notebook.\n",
    "\n",
    "We need to install `langgraph` module, run following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL CONTAINS SOME COMMON FUNCTIONS WE WILL USE, RUN THIS CELL BEFORE MOVING FORWARD\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_llm_response(message: str) -> tuple[str, str, str]:\n",
    "    lines_of_output = message.splitlines()\n",
    "    in_source_file = False\n",
    "    in_reasoning = False\n",
    "    in_additional_details = False\n",
    "    source_file = \"\"\n",
    "    reasoning = \"\"\n",
    "    additional_details = \"\"\n",
    "    for line in lines_of_output:\n",
    "        # trunk-ignore(cspell/error)\n",
    "        if re.match(r\"(?:##|\\*\\*)\\s+[Rr]easoning\", line.strip()):\n",
    "            in_reasoning = True\n",
    "            in_source_file = False\n",
    "            in_additional_details = False\n",
    "            continue\n",
    "        # trunk-ignore(cspell/error)\n",
    "        if re.match(r\"(?:##|\\*\\*)\\s+[Uu]pdated.*[Ff]ile\", line.strip()):\n",
    "            in_source_file = True\n",
    "            in_reasoning = False\n",
    "            in_additional_details = False\n",
    "            continue\n",
    "        # trunk-ignore(cspell/error)\n",
    "        if re.match(r\"(?:##|\\*\\*)\\s+[Aa]dditional\\s+[Ii]nformation\", line.strip()):\n",
    "            in_reasoning = False\n",
    "            in_source_file = False\n",
    "            in_additional_details = True\n",
    "            continue\n",
    "        if in_source_file:\n",
    "            if re.match(r\"```(?:\\w*)\", line):\n",
    "                continue\n",
    "            source_file = \"\\n\".join([source_file, line])\n",
    "        if in_reasoning:\n",
    "            reasoning = \"\\n\".join([reasoning, line])\n",
    "        if in_additional_details:\n",
    "            additional_details = \"\\n\".join([additional_details, line])\n",
    "    return source_file, reasoning, additional_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the analysis fix agent and generate a few example fixes to be used with file operation agents. \n",
    "\n",
    "The example issues are taken from Coolstore application analysis and can be found in [example_prompts](./example_prompts/) directory.\n",
    "\n",
    "Running the following cell will generate analysis fixes for all examples and store them in variables for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# fix generation agent\n",
    "fix_gen_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    name=\"fix_gen_agent\",\n",
    "    prompt=\"You are an experienced Java developer, who specializes in migrating code from Java EE to Quarkus\",\n",
    "    tools=[],\n",
    ")\n",
    "\n",
    "raw_response_ex1 = fix_gen_agent.invoke({\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=Path(\"example_prompts\", \"inventory_notification_java\", \"jms-to-reactive-quarkus-00050\").read_text()),\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use following additional info for Example-1:\n",
      "\n",
      "\n",
      "- Ensure your `pom.xml` includes the necessary Quarkus SmallRye Reactive Messaging dependencies. For example:\n",
      "  ```xml\n",
      "  <dependency>\n",
      "    <groupId>io.quarkus</groupId>\n",
      "    <artifactId>quarkus-smallrye-reactive-messaging</artifactId>\n",
      "  </dependency>\n",
      "  ```\n",
      "- Configure the messaging channel in `application.properties` to connect to your message broker.\n",
      "- This refactor assumes that somewhere in the application's configuration, the channel with the name `\"orders\"` is set up.\n",
      "- Further migration steps might include migrating other Java EE specific annotations and configurations to their Quarkus equivalents.\n"
     ]
    }
   ],
   "source": [
    "_, _, additional_info_ex1 = parse_llm_response(raw_response_ex1[\"messages\"][-1].content)\n",
    "print(\"We will use following additional info for Example-1:\")\n",
    "print(additional_info_ex1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Operations Agent\n",
    "\n",
    "This is the agent that will take \"Additional Information\" generated by previous agent as input and take actions if there is anything important in additional information. \n",
    "\n",
    "The actions include:\n",
    " * updating an existing file (which may not be same as the original file we fixed)\n",
    " * deleting a file\n",
    " * creating a new file\n",
    "\n",
    "The agent will use following tools to take the above options:\n",
    " * find: Finds relevant files in the project\n",
    " * read: Reads a file in the project\n",
    " * write: Writes content to a file in the project\n",
    " * rm: Removes a file from the project\n",
    "\n",
    "In the following cell, we define these tools and the agent.\n",
    "\n",
    "The [project](./project/) directory is the base of the project and will be used by the agent to perform file operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_r97mhoOlCxYtNBlJvj4FzFyH', 'function': {'arguments': '{\"file_name_pattern\":\"**/pom.xml\"}', 'name': 'find'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 496, 'total_tokens': 515, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-be4a4137-0eca-4faf-80d0-c1df0f511572-0', tool_calls=[{'name': 'find', 'args': {'file_name_pattern': '**/pom.xml'}, 'id': 'call_r97mhoOlCxYtNBlJvj4FzFyH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 496, 'output_tokens': 19, 'total_tokens': 515, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml', name='find', id='998a1568-9563-4de6-a20a-9ba1d8c2a5c1', tool_call_id='call_r97mhoOlCxYtNBlJvj4FzFyH')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_CMMZUntPQWq19jAWuOUfgK3S', 'function': {'arguments': '{\"file_name\":\"/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml\"}', 'name': 'read'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 541, 'total_tokens': 575, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4d91d4cf-b1f1-410c-8207-1e42e8fc52b0-0', tool_calls=[{'name': 'read', 'args': {'file_name': '/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml'}, 'id': 'call_CMMZUntPQWq19jAWuOUfgK3S', 'type': 'tool_call'}], usage_metadata={'input_tokens': 541, 'output_tokens': 34, 'total_tokens': 575, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='Here are the file contents:\\n```<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<project \\n    xmlns=\"http://maven.apache.org/POM/4.0.0\" \\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\\n    <modelVersion>4.0.0</modelVersion>\\n    <groupId>com.redhat.coolstore</groupId>\\n    <artifactId>monolith</artifactId>\\n    <version>1.0.0-SNAPSHOT</version>\\n    <packaging>war</packaging>\\n    <name>coolstore-monolith</name>\\n    <properties>\\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\\n        <maven.build.timestamp.format>yyyyMMdd\\'T\\'HHmmss</maven.build.timestamp.format>\\n        <project.encoding>UTF-8</project.encoding>\\n        <maven.test.skip>true</maven.test.skip>\\n    </properties>\\n    <dependencies>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-web-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.jms</groupId>\\n            <artifactId>jboss-jms-api_2.0_spec</artifactId>\\n            <version>2.0.0.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.flywaydb</groupId>\\n            <artifactId>flyway-core</artifactId>\\n            <version>4.1.2</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.rmi</groupId>\\n            <artifactId>jboss-rmi-api_1.0_spec</artifactId>\\n            <version>1.0.2.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-resteasy</artifactId>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-arc</artifactId>\\n        </dependency>\\n    </dependencies>\\n    <build>\\n        <finalName>ROOT</finalName>\\n        <plugins>\\n            <plugin>\\n                <artifactId>maven-compiler-plugin</artifactId>\\n                <version>3.0</version>\\n                <configuration>\\n                    <encoding>${project.encoding}</encoding>\\n                    <source>1.8</source>\\n                    <target>1.8</target>\\n                </configuration>\\n            </plugin>\\n            <plugin>\\n                <groupId>org.apache.maven.plugins</groupId>\\n                <artifactId>maven-war-plugin</artifactId>\\n                <version>3.2.0</version>\\n            </plugin>\\n        </plugins>\\n    </build>\\n    <profiles>\\n<!-- TODO: Add OpenShift profile here -->\\n    </profiles>\\n</project>```', name='read', id='09a31109-46b8-46d9-b9aa-80811271b287', tool_call_id='call_CMMZUntPQWq19jAWuOUfgK3S')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9QO4sa50zqe4nb3Rovy5LNml', 'function': {'arguments': '{\"file_name\":\"/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml\",\"content\":\"<?xml version=\\\\\"1.0\\\\\" encoding=\\\\\"UTF-8\\\\\"?>\\\\n<project \\\\n    xmlns=\\\\\"http://maven.apache.org/POM/4.0.0\\\\\" \\\\n    xmlns:xsi=\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\" xsi:schemaLocation=\\\\\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\\\\\">\\\\n    <modelVersion>4.0.0</modelVersion>\\\\n    <groupId>com.redhat.coolstore</groupId>\\\\n    <artifactId>monolith</artifactId>\\\\n    <version>1.0.0-SNAPSHOT</version>\\\\n    <packaging>war</packaging>\\\\n    <name>coolstore-monolith</name>\\\\n    <properties>\\\\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\\\\n        <maven.build.timestamp.format>yyyyMMdd\\'T\\'HHmmss</maven.build.timestamp.format>\\\\n        <project.encoding>UTF-8</project.encoding>\\\\n        <maven.test.skip>true</maven.test.skip>\\\\n    </properties>\\\\n    <dependencies>\\\\n        <dependency>\\\\n            <groupId>javax</groupId>\\\\n            <artifactId>javaee-web-api</artifactId>\\\\n            <version>7.0</version>\\\\n            <scope>provided</scope>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>javax</groupId>\\\\n            <artifactId>javaee-api</artifactId>\\\\n            <version>7.0</version>\\\\n            <scope>provided</scope>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>org.jboss.spec.javax.jms</groupId>\\\\n            <artifactId>jboss-jms-api_2.0_spec</artifactId>\\\\n            <version>2.0.0.Final</version>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>org.flywaydb</groupId>\\\\n            <artifactId>flyway-core</artifactId>\\\\n            <version>4.1.2</version>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>org.jboss.spec.javax.rmi</groupId>\\\\n            <artifactId>jboss-rmi-api_1.0_spec</artifactId>\\\\n            <version>1.0.2.Final</version>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>io.quarkus</groupId>\\\\n            <artifactId>quarkus-resteasy</artifactId>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>io.quarkus</groupId>\\\\n            <artifactId>quarkus-arc</artifactId>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>io.quarkus</groupId>\\\\n            <artifactId>quarkus-smallrye-reactive-messaging</artifactId>\\\\n        </dependency>\\\\n    </dependencies>\\\\n    <build>\\\\n        <finalName>ROOT</finalName>\\\\n        <plugins>\\\\n            <plugin>\\\\n                <artifactId>maven-compiler-plugin</artifactId>\\\\n                <version>3.0</version>\\\\n                <configuration>\\\\n                    <encoding>${project.encoding}</encoding>\\\\n                    <source>1.8</source>\\\\n                    <target>1.8</target>\\\\n                </configuration>\\\\n            </plugin>\\\\n            <plugin>\\\\n                <groupId>org.apache.maven.plugins</groupId>\\\\n                <artifactId>maven-war-plugin</artifactId>\\\\n                <version>3.2.0</version>\\\\n            </plugin>\\\\n        </plugins>\\\\n    </build>\\\\n    <profiles>\\\\n<!-- TODO: Add OpenShift profile here -->\\\\n    </profiles>\\\\n</project>\"}', 'name': 'write'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 887, 'prompt_tokens': 1318, 'total_tokens': 2205, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2c8f7fb4-9736-486e-adaa-80f377ea8e5d-0', tool_calls=[{'name': 'write', 'args': {'file_name': '/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml', 'content': '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<project \\n    xmlns=\"http://maven.apache.org/POM/4.0.0\" \\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\\n    <modelVersion>4.0.0</modelVersion>\\n    <groupId>com.redhat.coolstore</groupId>\\n    <artifactId>monolith</artifactId>\\n    <version>1.0.0-SNAPSHOT</version>\\n    <packaging>war</packaging>\\n    <name>coolstore-monolith</name>\\n    <properties>\\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\\n        <maven.build.timestamp.format>yyyyMMdd\\'T\\'HHmmss</maven.build.timestamp.format>\\n        <project.encoding>UTF-8</project.encoding>\\n        <maven.test.skip>true</maven.test.skip>\\n    </properties>\\n    <dependencies>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-web-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.jms</groupId>\\n            <artifactId>jboss-jms-api_2.0_spec</artifactId>\\n            <version>2.0.0.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.flywaydb</groupId>\\n            <artifactId>flyway-core</artifactId>\\n            <version>4.1.2</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.rmi</groupId>\\n            <artifactId>jboss-rmi-api_1.0_spec</artifactId>\\n            <version>1.0.2.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-resteasy</artifactId>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-arc</artifactId>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-smallrye-reactive-messaging</artifactId>\\n        </dependency>\\n    </dependencies>\\n    <build>\\n        <finalName>ROOT</finalName>\\n        <plugins>\\n            <plugin>\\n                <artifactId>maven-compiler-plugin</artifactId>\\n                <version>3.0</version>\\n                <configuration>\\n                    <encoding>${project.encoding}</encoding>\\n                    <source>1.8</source>\\n                    <target>1.8</target>\\n                </configuration>\\n            </plugin>\\n            <plugin>\\n                <groupId>org.apache.maven.plugins</groupId>\\n                <artifactId>maven-war-plugin</artifactId>\\n                <version>3.2.0</version>\\n            </plugin>\\n        </plugins>\\n    </build>\\n    <profiles>\\n<!-- TODO: Add OpenShift profile here -->\\n    </profiles>\\n</project>'}, 'id': 'call_9QO4sa50zqe4nb3Rovy5LNml', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1318, 'output_tokens': 887, 'total_tokens': 2205, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='Successfully wrote contents to file /Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml', name='write', id='f6c43341-a1b0-4389-a76b-8f27ed9c7642', tool_call_id='call_9QO4sa50zqe4nb3Rovy5LNml')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gxoYegKLZjF5028xSCAcaf08', 'function': {'arguments': '{\"file_name_pattern\":\"**/application.properties\"}', 'name': 'find'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 2236, 'total_tokens': 2255, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2176}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7d0d9984-af24-4d94-a365-18d9fd5947a3-0', tool_calls=[{'name': 'find', 'args': {'file_name_pattern': '**/application.properties'}, 'id': 'call_gxoYegKLZjF5028xSCAcaf08', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2236, 'output_tokens': 19, 'total_tokens': 2255, 'input_token_details': {'audio': 0, 'cache_read': 2176}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='No files found matching pattern **/application.properties', name='find', id='ba81a777-ecfd-4798-91a6-ad1ddffc393a', tool_call_id='call_gxoYegKLZjF5028xSCAcaf08')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ci5Ftp9FCJEH9iR30AtpuxgV', 'function': {'arguments': '{\"file_name\":\"/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/src/main/resources/application.properties\",\"content\":\"# Configure the \\'orders\\' channel for SmallRye Reactive Messaging\\\\nmp.messaging.incoming.orders.connector=smallrye-kafka\\\\nmp.messaging.incoming.orders.topic=orders-topic\\\\nmp.messaging.incoming.orders.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer\\\\n\\\\nmp.messaging.outgoing.orders.connector=smallrye-kafka\\\\nmp.messaging.outgoing.orders.topic=processed-orders-topic\\\\nmp.messaging.outgoing.orders.value.serializer=org.apache.kafka.common.serialization.StringSerializer\\\\n\"}', 'name': 'write'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 134, 'prompt_tokens': 2270, 'total_tokens': 2404, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2176}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2226bc66-5f0e-44db-a21b-7a8ac3986d4a-0', tool_calls=[{'name': 'write', 'args': {'file_name': '/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/src/main/resources/application.properties', 'content': \"# Configure the 'orders' channel for SmallRye Reactive Messaging\\nmp.messaging.incoming.orders.connector=smallrye-kafka\\nmp.messaging.incoming.orders.topic=orders-topic\\nmp.messaging.incoming.orders.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer\\n\\nmp.messaging.outgoing.orders.connector=smallrye-kafka\\nmp.messaging.outgoing.orders.topic=processed-orders-topic\\nmp.messaging.outgoing.orders.value.serializer=org.apache.kafka.common.serialization.StringSerializer\\n\"}, 'id': 'call_ci5Ftp9FCJEH9iR30AtpuxgV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2270, 'output_tokens': 134, 'total_tokens': 2404, 'input_token_details': {'audio': 0, 'cache_read': 2176}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='Successfully wrote contents to file /Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/src/main/resources/application.properties', name='write', id='99f76e9b-53a2-4cd3-bc4b-32e5c13da969', tool_call_id='call_ci5Ftp9FCJEH9iR30AtpuxgV')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='I have successfully added the necessary Quarkus SmallRye Reactive Messaging dependency to your `pom.xml`. Additionally, I\\'ve created the `application.properties` file to configure the messaging channel named `\"orders\"` to connect to a message broker using Kafka. If there are further configurations or migrations needed, please let me know!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 2437, 'total_tokens': 2502, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2304}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None}, id='run-85105987-f022-41ef-9080-dde64eb5cf0e-0', usage_metadata={'input_tokens': 2437, 'output_tokens': 65, 'total_tokens': 2502, 'input_token_details': {'audio': 0, 'cache_read': 2304}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated\n",
    "\n",
    "@tool\n",
    "def find(file_name_pattern: Annotated[str, \"Glob pattern to match file names\"]) -> Annotated[str, \"Absolute paths of the files found separated by newlines\"]:\n",
    "    \"\"\"Given a glob pattern, searches for files matching the pattern in project and returns absolute paths of the files\n",
    "\n",
    "    Returns:\n",
    "        str: Newline separated list of filepaths\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matching_files = glob.glob(\"./project/\" + file_name_pattern, recursive=True)\n",
    "    except Exception as e:\n",
    "        return f\"Failed to search for files because of error - {e}\"\n",
    "    absolute_paths = [os.path.abspath(file) for file in matching_files]\n",
    "    if not absolute_paths:\n",
    "        return f\"No files found matching pattern {file_name_pattern}\"\n",
    "    return \"\\n\".join(absolute_paths)\n",
    "\n",
    "@tool\n",
    "def read(file_name: Annotated[str, \"Absolute path to the file to read\"]):\n",
    "    \"\"\"Given an absolute path to a file, reads the file and returns content\"\"\"\n",
    "    if os.path.exists(file_name):\n",
    "        contents = \"\"\n",
    "        with open(file_name, \"r\") as f:\n",
    "            contents = f.read()\n",
    "        return f\"Here are the file contents:\\n```{contents}```\"\n",
    "    return f\"File {file_name} does not exist\"\n",
    "\n",
    "@tool\n",
    "def write(file_name: Annotated[str, \"Absolute path to the file\"], content: Annotated[str, \"Content to write to the file\"]):\n",
    "    \"\"\"Given an absolute path to a file and the content, writes content to the file. If the file doesn't exist, creates a new file.\n",
    "    If the directories dont exist, creates all parent directories.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "        with open(file_name, \"w+\") as f:\n",
    "            f.write(content)\n",
    "        return f\"Successfully wrote contents to file {file_name}\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to write to file with error {e}\"\n",
    "\n",
    "@tool\n",
    "def rm(file: Annotated[str, \"Full path of the file to remove\"]):\n",
    "    \"\"\"Removes file\"\"\"\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        return \"Removed the file\"\n",
    "    return f\"File {file} does not exist\"\n",
    "\n",
    "file_ops_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[find, read, write, rm],\n",
    "    prompt=\"\"\"You are an expert Java developer. You are asked to make changes in a Java project.\n",
    "You can either update an existing file, delete a file, or create a new file with relevant content.\n",
    "To update or delete an existing file, search for the file to update using a glob pattern, and determine which file to update from the files found.\n",
    "To update an existing file, make sure you read the file to get existing contents, and then write to the file updated content.\n",
    "If a file doesn't exist and needs to be created, create that file.\n",
    "Always use absolute file paths to make changes to files. You are given tools to perform file operations. Use the tools, and make the changes needed.\n",
    "Use your best judgement to solve the issues described.\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "for state in file_ops_agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=additional_info_ex1)]},\n",
    "    stream_mode=[\"updates\"]\n",
    "):\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "In the above output, you can see that the model searched for `pom.xml` file and added the dependency. \n",
    "\n",
    "It also searched for `application.properties` file but it wasn't found, so it created a new file at path `src/main/resources` which is the correct path for Quarkus applications. \n",
    "\n",
    "This proves the possibility of updating another file from the project, AND creating a new file.\n",
    "\n",
    "I have attached screenshots of the results from my environment below.\n",
    "\n",
    "![pom_xml_update](./screenshots/pom_xml_update.png)\n",
    "\n",
    "![application_properties_creation](./screenshots/application_properties_creation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Removal Example\n",
    "\n",
    "Lets take a look at another example where we have to remove a `web.xml` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BErckULSix64WOTimSabFREt', 'function': {'arguments': '{\"file_name_pattern\":\"**/beans.xml\"}', 'name': 'find'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 486, 'total_tokens': 505, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e6e94688-0c50-4a39-b16d-ff9e3cb17734-0', tool_calls=[{'name': 'find', 'args': {'file_name_pattern': '**/beans.xml'}, 'id': 'call_BErckULSix64WOTimSabFREt', 'type': 'tool_call'}], usage_metadata={'input_tokens': 486, 'output_tokens': 19, 'total_tokens': 505, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/beans.xml', name='find', id='f190cbae-6ddc-41a9-a2ab-afd992938b0b', tool_call_id='call_BErckULSix64WOTimSabFREt')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fhQHwDs0ZhAW9zGLUSfZZ8Wm', 'function': {'arguments': '{\"file\":\"/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/beans.xml\"}', 'name': 'rm'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 531, 'total_tokens': 564, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-34a04dd6-b1d1-4884-a318-587bdaded097-0', tool_calls=[{'name': 'rm', 'args': {'file': '/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/beans.xml'}, 'id': 'call_fhQHwDs0ZhAW9zGLUSfZZ8Wm', 'type': 'tool_call'}], usage_metadata={'input_tokens': 531, 'output_tokens': 33, 'total_tokens': 564, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='Removed the file', name='rm', id='4f8bef7a-7ff1-4e97-aacd-40e8918d896d', tool_call_id='call_fhQHwDs0ZhAW9zGLUSfZZ8Wm')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gDENcPLEM8eJMewCkxPACMeA', 'function': {'arguments': '{\"file_name_pattern\":\"**/pom.xml\"}', 'name': 'find'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 573, 'total_tokens': 592, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-27b77fa0-2213-405d-861e-7bcd531e5eba-0', tool_calls=[{'name': 'find', 'args': {'file_name_pattern': '**/pom.xml'}, 'id': 'call_gDENcPLEM8eJMewCkxPACMeA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 573, 'output_tokens': 19, 'total_tokens': 592, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml', name='find', id='12f5f85f-437c-4ff1-832c-0c671efbf8a8', tool_call_id='call_gDENcPLEM8eJMewCkxPACMeA')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hStsAd7uxMxG7kHaaH2S9YcM', 'function': {'arguments': '{\"file_name\":\"/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml\"}', 'name': 'read'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 618, 'total_tokens': 652, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e22505ba-69d0-4e9d-9ecb-7e041d36f2dd-0', tool_calls=[{'name': 'read', 'args': {'file_name': '/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml'}, 'id': 'call_hStsAd7uxMxG7kHaaH2S9YcM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 618, 'output_tokens': 34, 'total_tokens': 652, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='Here are the file contents:\\n```<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<project \\n    xmlns=\"http://maven.apache.org/POM/4.0.0\" \\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\\n    <modelVersion>4.0.0</modelVersion>\\n    <groupId>com.redhat.coolstore</groupId>\\n    <artifactId>monolith</artifactId>\\n    <version>1.0.0-SNAPSHOT</version>\\n    <packaging>war</packaging>\\n    <name>coolstore-monolith</name>\\n    <properties>\\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\\n        <maven.build.timestamp.format>yyyyMMdd\\'T\\'HHmmss</maven.build.timestamp.format>\\n        <project.encoding>UTF-8</project.encoding>\\n        <maven.test.skip>true</maven.test.skip>\\n    </properties>\\n    <dependencies>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-web-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.jms</groupId>\\n            <artifactId>jboss-jms-api_2.0_spec</artifactId>\\n            <version>2.0.0.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.flywaydb</groupId>\\n            <artifactId>flyway-core</artifactId>\\n            <version>4.1.2</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.rmi</groupId>\\n            <artifactId>jboss-rmi-api_1.0_spec</artifactId>\\n            <version>1.0.2.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-resteasy</artifactId>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-arc</artifactId>\\n        </dependency>\\n    </dependencies>\\n    <build>\\n        <finalName>ROOT</finalName>\\n        <plugins>\\n            <plugin>\\n                <artifactId>maven-compiler-plugin</artifactId>\\n                <version>3.0</version>\\n                <configuration>\\n                    <encoding>${project.encoding}</encoding>\\n                    <source>1.8</source>\\n                    <target>1.8</target>\\n                </configuration>\\n            </plugin>\\n            <plugin>\\n                <groupId>org.apache.maven.plugins</groupId>\\n                <artifactId>maven-war-plugin</artifactId>\\n                <version>3.2.0</version>\\n            </plugin>\\n        </plugins>\\n    </build>\\n    <profiles>\\n<!-- TODO: Add OpenShift profile here -->\\n    </profiles>\\n</project>```', name='read', id='bec5ee37-5afe-4480-9514-197deda81ef0', tool_call_id='call_hStsAd7uxMxG7kHaaH2S9YcM')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content=\"The `pom.xml` file already includes the necessary CDI dependencies for Quarkus support, namely `quarkus-resteasy` and `quarkus-arc`. \\n\\nHere's a summary of the changes made and the current status:\\n- **Removed `beans.xml`:** The `beans.xml` file was successfully removed.\\n- **Verified Dependencies:** The `pom.xml` file contains the `quarkus-resteasy` and `quarkus-arc` extensions, ensuring CDI support in the application.\\n\\nNext, ensure that the application is tested properly to verify that CDI is functioning as expected without the `beans.xml` file. Additionally, refer to the [Quarkus CDI Guide](https://quarkus.io/guides/cdi) for more details on handling CDI with Quarkus.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 166, 'prompt_tokens': 1395, 'total_tokens': 1561, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None}, id='run-3c8f1d8e-d7c5-4925-a4a9-80a2dc3bbfe7-0', usage_metadata={'input_tokens': 1395, 'output_tokens': 166, 'total_tokens': 1561, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n"
     ]
    }
   ],
   "source": [
    "additional_info_ex2 = \"\"\"- **Documentation Reference:** For more details on how Quarkus handles CDI, refer to the [Quarkus CDI Guide](https://quarkus.io/guides/cdi).\n",
    "- **Testing:** After removing `beans.xml`, ensure that the application is tested to verify that CDI is functioning as expected without the file.\n",
    "- **Dependencies:** Double-check the `pom.xml` to ensure all necessary CDI dependencies are included for Quarkus. This typically involves ensuring that the `quarkus-resteasy` or `quarkus-arc` extensions are present, as they provide CDI support.\"\"\"\n",
    "\n",
    "for state in file_ops_agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=additional_info_ex2)]},\n",
    "    stream_mode=[\"updates\"]\n",
    "):\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We can see that the `beans.xml` file is removed by the agent. See screenshot below:\n",
    "\n",
    "![beans_removal](./screenshots/beans_xml_removal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating tool usage with different providers via Model Provider\n",
    "\n",
    "This section validates that we are able to use tools with different Model Providers we support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "\n",
    "@tool\n",
    "def get_temperature(city: Annotated[str, \"Name of the city\"]):\n",
    "    \"\"\"Returns current temperature in given city\"\"\"\n",
    "    return f\"Current temperature in {city} is 80 degrees.\"\n",
    "\n",
    "def validate(model: LanguageModelLike, **kwargs):\n",
    "    agent = create_react_agent(\n",
    "        model=model,\n",
    "        tools=[get_temperature],\n",
    "        prompt=\"Help the user with their queries, use the tools at your disposal.\",\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    for r in agent.stream({\"messages\": [(\"user\", \"What is the current temperature in New York?\")]}):\n",
    "        print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on which model you test this with, you need to set up your API keys for the model before running the \"validation\" cell. Every cell has a comment at top about the environment variable expected.\n",
    "\n",
    "You will set the keys in `.env` file at the project root and run the following cell for changes to take effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "|   Kai Model Provider   |      Model       |  Works?  |\n",
    "| ---------------------- | ---------------- | -------- |\n",
    "| ChatOpenAI             | gpt-3.5-turbo    |  &check; |\n",
    "| ChatOpenAI (RH Maas)   | granite-8b       |  &check; |\n",
    "| ChatOpenAI (RH Maas)   | llama-7b         |  &check; |\n",
    "| ChatBedrock            | llama-70b-v1     |  &cross; |\n",
    "| ChatBedrock            | llama-70b-v2     |  &cross; |\n",
    "| ChatBedrock            | claude-3-sonnet  |  &check; |\n",
    "| ChatGoogleGenAI        | gemini-2.0-flash |  &check; |\n",
    "| ChatDeepSeek           | deepseek-chat    |  &check; |\n",
    "\n",
    "Following model providers are not tested yet:\n",
    "\n",
    "* ChatOllama\n",
    "* ChatAzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-93d38e3ef7764368aeab44edfa14db42', 'function': {'arguments': '{\"city\": \"New York\"}', 'name': 'get_temperature'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 140, 'total_tokens': 165, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'granite-3-8b-instruct', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-97df9c64-fad3-4df2-b314-76b4fc50324e-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': 'chatcmpl-tool-93d38e3ef7764368aeab44edfa14db42', 'type': 'tool_call'}], usage_metadata={'input_tokens': 140, 'output_tokens': 25, 'total_tokens': 165, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='92aee6a7-fc0c-4137-991f-dfbdbd915f92', tool_call_id='chatcmpl-tool-93d38e3ef7764368aeab44edfa14db42')]}}\n",
      "{'agent': {'messages': [AIMessage(content='The current temperature in New York is 80 degrees.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 161, 'total_tokens': 174, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'granite-3-8b-instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-efec3793-40ed-4125-96ea-8dfdb247961a-0', usage_metadata={'input_tokens': 161, 'output_tokens': 13, 'total_tokens': 174, 'input_token_details': {}, 'output_token_details': {}})]}}\n"
     ]
    }
   ],
   "source": [
    "## Test with granite-8b on RH maas via ChatOpenAI\n",
    "## Env vars needed:\n",
    "## PARASOL_GRANITE_KEY - api key\n",
    "## PARASON_GRANITE_API - base url (usually ends with /v1)\n",
    "\n",
    "from kai.llm_interfacing.model_provider import ChatOpenAI\n",
    "\n",
    "validate(ChatOpenAI(\n",
    "    api_key=os.environ[\"PARASOL_GRANITE_KEY\"],\n",
    "    base_url=os.environ[\"PARASOL_GRANITE_API\"],\n",
    "    model_name=\"granite-3-8b-instruct\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-671b7256d3e94bed833385429a6d5168', 'function': {'arguments': '{\"city\": \"New York\"}', 'name': 'get_temperature'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 206, 'total_tokens': 224, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-fe619e78-3d5f-4814-8a78-a4f9b24d9b7d-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': 'chatcmpl-tool-671b7256d3e94bed833385429a6d5168', 'type': 'tool_call'}], usage_metadata={'input_tokens': 206, 'output_tokens': 18, 'total_tokens': 224, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='ba529951-2d5f-4a2c-82ef-1dcf4bbac5fd', tool_call_id='chatcmpl-tool-671b7256d3e94bed833385429a6d5168')]}}\n",
      "{'agent': {'messages': [AIMessage(content=\"I used the hypothetical output of the function to create a sample response. However, in a real scenario, the function would return the actual temperature value as per the actual output of the 'get_temperature' function.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 249, 'total_tokens': 292, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-496d77f3-4914-46a8-90ac-225c3c7b2011-0', usage_metadata={'input_tokens': 249, 'output_tokens': 43, 'total_tokens': 292, 'input_token_details': {}, 'output_token_details': {}})]}}\n"
     ]
    }
   ],
   "source": [
    "validate(ChatOpenAI(\n",
    "    api_key=os.environ[\"PARASOL_LLAMA_KEY\"],\n",
    "    base_url=os.environ[\"PARASOL_LLAMA_API\"],\n",
    "    model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hyQWUzmMBoWcy7lgjdtKMqKK', 'function': {'arguments': '{\"city\":\"New York\"}', 'name': 'get_temperature'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 75, 'total_tokens': 91, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ef88bd74-8e49-47b8-a583-ad33145a439f-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': 'call_hyQWUzmMBoWcy7lgjdtKMqKK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 75, 'output_tokens': 16, 'total_tokens': 91, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='7339a847-6267-4964-8f81-0c3ca9a3c4e0', tool_call_id='call_hyQWUzmMBoWcy7lgjdtKMqKK')]}}\n",
      "{'agent': {'messages': [AIMessage(content='The current temperature in New York is 80 degrees.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 108, 'total_tokens': 121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-176cd009-bd24-40c6-be5c-dd29a95bfd59-0', usage_metadata={'input_tokens': 108, 'output_tokens': 13, 'total_tokens': 121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "## Test with gpt-3.5-turbo via ChatOpenAI\n",
    "## Env vars needed:\n",
    "## OPENAI_API_KEY - api key\n",
    "\n",
    "validate(ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_temperature', 'arguments': '{\"city\": \"New York\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-0345ec89-e933-4a1a-9645-ca54d4a3d3b6-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': '84239db4-b642-4c92-9a83-ec759f341dff', 'type': 'tool_call'}], usage_metadata={'input_tokens': 38, 'output_tokens': 6, 'total_tokens': 44, 'input_token_details': {'cache_read': 0}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='5ed17fd0-c2b7-4f5a-9449-0c1287060c19', tool_call_id='84239db4-b642-4c92-9a83-ec759f341dff')]}}\n",
      "{'agent': {'messages': [AIMessage(content='The current temperature in New York is 80 degrees.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-9e6ccb8d-9110-4cee-94db-a6085ffffed8-0', usage_metadata={'input_tokens': 59, 'output_tokens': 13, 'total_tokens': 72, 'input_token_details': {'cache_read': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "## Test with gemini-2.0-flash via GoogleGenAI\n",
    "## Env vars needed:\n",
    "## GEMINI_API_KEY - api key\n",
    "\n",
    "from kai.llm_interfacing.model_provider import ChatGoogleGenerativeAI\n",
    "\n",
    "validate(ChatGoogleGenerativeAI(\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    model=\"gemini-2.0-flash\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"I'm just an AI, I don't have access to real-time weather data. However, I can suggest some ways for you to find out the current temperature in New York:\\n\\n1. Check online weather websites: You can check websites like AccuWeather, Weather.com, or the National Weather Service (NWS) for the current temperature in New York.\\n2. Use a weather app: You can download a weather app on your smartphone, such as Dark Sky or Weather Underground, which can provide you with real-time weather information, including the current temperature.\\n3. Check social media: Many weather organizations and meteorologists share current weather conditions, including temperature, on social media platforms like Twitter and Facebook.\\n4. Tune into local news: You can watch local news or listen to local radio stations to get the current temperature and weather forecast for New York.\\n\\nPlease note that the temperature can change rapidly, so it's always a good idea to check multiple sources for the most up-to-date information.\", additional_kwargs={'usage': {'prompt_tokens': 39, 'completion_tokens': 200, 'total_tokens': 239}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-1-70b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 39, 'completion_tokens': 200, 'total_tokens': 239}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-1-70b-instruct-v1:0'}, id='run-e5b9bdad-42ca-4706-87d3-45b911b4d674-0', usage_metadata={'input_tokens': 39, 'output_tokens': 200, 'total_tokens': 239})]}}\n"
     ]
    }
   ],
   "source": [
    "## Test with llama-70b via Bedrock\n",
    "## Env vars needed:\n",
    "## AWS_ACCESS_KEY_ID\n",
    "## AWS_SECRET_ACCESS_KEY\n",
    "\n",
    "from kai.llm_interfacing.model_provider import ChatBedrock\n",
    "\n",
    "validate(ChatBedrock(\n",
    "    model=\"us.meta.llama3-1-70b-instruct-v1:0\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"I'm just an AI, I don't have real-time access to current weather conditions. However, I can suggest some ways for you to find out the current temperature in New York.\\n\\nYou can check the current weather forecast for New York on websites like:\\n\\n* National Weather Service (NWS) - [www.weather.gov](http://www.weather.gov)\\n* AccuWeather - [www.accuweather.com](http://www.accuweather.com)\\n* Weather.com - [www.weather.com](http://www.weather.com)\\n* Google Maps - [maps.google.com](http://maps.google.com) (look for the weather icon)\\n\\nYou can also check your local news or weather app on your smartphone for the current temperature in New York.\\n\\nIf you're looking for a more specific answer, I can try to help you with that. What city in New York are you looking for the temperature in?\", additional_kwargs={'usage': {'prompt_tokens': 39, 'completion_tokens': 182, 'total_tokens': 221}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-2-1b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 39, 'completion_tokens': 182, 'total_tokens': 221}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-2-1b-instruct-v1:0'}, id='run-43bcbfbb-00fb-4616-ab8b-b1aaadee2f32-0', usage_metadata={'input_tokens': 39, 'output_tokens': 182, 'total_tokens': 221})]}}\n"
     ]
    }
   ],
   "source": [
    "validate(ChatBedrock(\n",
    "    model=\"us.meta.llama3-2-1b-instruct-v1:0\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='I\\'m just an AI, I don\\'t have access to real-time information or current weather conditions. But I can suggest some ways for you to find out the current temperature in New York:\\n\\n1. Check online weather websites: You can check websites like AccuWeather, Weather.com, or the National Weather Service (NWS) for current weather conditions and temperature in New York.\\n2. Use a search engine: You can simply type \"current temperature in New York\" or \"New York weather\" in a search engine like Google, and it will show you the current temperature and weather conditions.\\n3. Check a weather app: If you have a smartphone, you can download a weather app like Dark Sky or Weather Underground, which can provide you with current weather conditions and temperature in New York.\\n4. Check social media: You can also check social media platforms like Twitter or Facebook for updates on the current weather in New York.\\n\\nPlease note that the temperature in New York can vary depending on the time of day, location, and other factors, so it\\'s always a good idea to check multiple sources for the most up-to-date information.', additional_kwargs={'usage': {'prompt_tokens': 40, 'completion_tokens': 229, 'total_tokens': 269}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-3-70b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 40, 'completion_tokens': 229, 'total_tokens': 269}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-3-70b-instruct-v1:0'}, id='run-8d93f8a0-197f-4851-88b4-a494678c7d59-0', usage_metadata={'input_tokens': 40, 'output_tokens': 229, 'total_tokens': 269})]}}\n"
     ]
    }
   ],
   "source": [
    "validate(ChatBedrock(\n",
    "    model=\"us.meta.llama3-3-70b-instruct-v1:0\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 253, 'completion_tokens': 54, 'total_tokens': 307}, 'stop_reason': 'tool_use', 'model_id': 'us.anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 253, 'completion_tokens': 54, 'total_tokens': 307}, 'stop_reason': 'tool_use', 'model_id': 'us.anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-ebe41a8a-c51b-4c47-b222-b73af17499b4-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': 'toolu_bdrk_01ACM8hMxuQHJeGnbQLDqqgz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 253, 'output_tokens': 54, 'total_tokens': 307})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='51824bd5-9d8e-4e26-8795-603c48d155c6', tool_call_id='toolu_bdrk_01ACM8hMxuQHJeGnbQLDqqgz')]}}\n",
      "{'agent': {'messages': [AIMessage(content='The current temperature in New York is 80 degrees Fahrenheit.', additional_kwargs={'usage': {'prompt_tokens': 329, 'completion_tokens': 19, 'total_tokens': 348}, 'stop_reason': 'end_turn', 'model_id': 'us.anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 329, 'completion_tokens': 19, 'total_tokens': 348}, 'stop_reason': 'end_turn', 'model_id': 'us.anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-128488f9-58ac-4baf-99a8-41e9b40bf676-0', usage_metadata={'input_tokens': 329, 'output_tokens': 19, 'total_tokens': 348})]}}\n"
     ]
    }
   ],
   "source": [
    "validate(ChatBedrock(\n",
    "    model=\"us.anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_1211c9dd-2ad1-43f3-8696-94c912284b06', 'function': {'arguments': '{\"city\":\"New York\"}', 'name': 'get_temperature'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 129, 'total_tokens': 149, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 128}, 'prompt_cache_hit_tokens': 128, 'prompt_cache_miss_tokens': 1}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4_prod0225', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06857c74-a5ef-4121-a4a5-590df9397845-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': 'call_0_1211c9dd-2ad1-43f3-8696-94c912284b06', 'type': 'tool_call'}], usage_metadata={'input_tokens': 129, 'output_tokens': 20, 'total_tokens': 149, 'input_token_details': {'cache_read': 128}, 'output_token_details': {}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='b4290fe8-05a3-474c-b7a9-5d005ec45cda', tool_call_id='call_0_1211c9dd-2ad1-43f3-8696-94c912284b06')]}}\n",
      "{'__interrupt__': ()}\n"
     ]
    }
   ],
   "source": [
    "# Env vars needed:\n",
    "# DEEPSEEK_API_KEY\n",
    "\n",
    "from kai.llm_interfacing.model_provider import ChatDeepSeek\n",
    "\n",
    "validate(model=ChatDeepSeek(\n",
    "    api_key=os.environ[\"DEEPSEEK_API_KEY\"],\n",
    "    model=\"deepseek-chat\",\n",
    "), interrupt_after=[\"tools\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using tools with models that do not support tool calling\n",
    "\n",
    "In this section, we experiment creating our own _LangGraph ToolNode_ and custom logic in the _Conditional Edge_ to enable models that don't support tools to call given tools. Note that we saw examples of models in previous sections that do not support tools out of the box. It is absolutely essential that we are able to use tools with any model if we have to use LangGraph approach for agents. We validate whether its possible to do that in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## we use meta-llama-70b provided via Bedrock in this section\n",
    "\n",
    "import json\n",
    "from typing import Optional, TypedDict\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage, SystemMessage, ToolMessage\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langchain.tools.render import render_text_description\n",
    "from kai.llm_interfacing.model_provider import ChatBedrock\n",
    "\n",
    "def _print_state(state: MessagesState):\n",
    "    print(\"...\"*15)\n",
    "    for idx, message in enumerate(state[\"messages\"]):\n",
    "        print(f\"{idx}: {message.content.splitlines()[0] if message.content else message.content}\")\n",
    "    print(\"...\"*15)\n",
    "\n",
    "@tool\n",
    "def get_temperature(city: Annotated[str, \"Name of the city\"]):\n",
    "    \"\"\"Returns current temperature in given city\"\"\"\n",
    "    return f\"Current temperature in {city} is 80 degrees.\"\n",
    "\n",
    "# define the tool node\n",
    "tool_node = ToolNode(tools=[get_temperature])\n",
    "\n",
    "# define the model provider\n",
    "model_provider = ChatBedrock(\n",
    "    model=\"us.meta.llama3-3-70b-instruct-v1:0\"\n",
    ")\n",
    "\n",
    "def extract_json_from_text(text):\n",
    "    \"\"\"Extracts JSON code block from a multiline string.\"\"\"\n",
    "    pattern = r\"```(json)?\\s*(\\{.*?\\})\\s*```\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        json_str = match.group(2)\n",
    "        try:\n",
    "            return json.loads(json_str)  # Convert to Python dict\n",
    "        except json.JSONDecodeError:\n",
    "            return None  # Invalid JSON format\n",
    "\n",
    "    return None\n",
    "\n",
    "# define the agent\n",
    "def agent_call(state: MessagesState):\n",
    "    # explain the tools here\n",
    "    sys_msg = f\"\"\"You are an intelligent assistant who can help users with their weather related queries. \n",
    "You may not know answers to all questions as some of the answers may depend on real time weather data. However, you are given tools you can use to access that data.\n",
    "Here is the schema of tools you are given:\n",
    "\n",
    "{render_text_description([get_temperature])}\n",
    "\n",
    "If you do need to call a tool, respond with a JSON object containing only two keys - tool_name and args. `tool_name` should be the name of the tool to call and `args` should be nested JSON containing the arguments to pass to the function in key value format.\n",
    "Make sure you always use ``` at the start and end of the JSON block to clearly separate it from text.\n",
    "If you have reached the answer, respond with text and add string 'FINAL ANSWER' to the beginning.\n",
    "\"\"\"\n",
    "    # insert tool description as sys message\n",
    "    if \"messages\" not in state or not state[\"messages\"] or \\\n",
    "        not isinstance(state[\"messages\"][0], SystemMessage):\n",
    "        state[\"messages\"].insert(0, SystemMessage(content=sys_msg))\n",
    "    \n",
    "    # ToolMessage is a special type of message that contains the tool response.\n",
    "    # our model doesn't understand that. we change it to a human message instead.\n",
    "    if isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        tool_output = state[\"messages\"][-1]\n",
    "        state[\"messages\"][-1] = HumanMessage(\n",
    "            content=f\"The output of tool {tool_output.name} is - {tool_output.content}\"\n",
    "        )\n",
    "    \n",
    "    response = model_provider.invoke(state[\"messages\"])\n",
    "\n",
    "    # our model does not set tool_calls on the response\n",
    "    # we parse the model response ourselves and convert\n",
    "    # it into an AIMessage with tool_calls set\n",
    "    if \"tool_name\" in response.content:\n",
    "        agent_response = extract_json_from_text(response.content)\n",
    "        if not agent_response:\n",
    "            return { \"messages\": [AIMessage(content=\"RETRY\")] }\n",
    "        response = AIMessage(\n",
    "            content=\"\",\n",
    "            tool_calls=[{\n",
    "                \"name\": agent_response.get(\"tool_name\"),\n",
    "                \"args\": agent_response.get(\"args\"),\n",
    "                \"type\": \"tool_call\",\n",
    "                \"id\": \"tool_call_id_1\",\n",
    "            }],\n",
    "        )\n",
    "    return { \"messages\": [response] }\n",
    "\n",
    "# this is the conditional edge to parse and\n",
    "# route the llm response to a tool\n",
    "def should_call_tool(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    if not last_message.content or \"RETRY\" in last_message.content:\n",
    "        return \"agent\"\n",
    "    return END\n",
    "    \n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"agent\", agent_call)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_call_tool, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================ Human Message =================================\n",
      "\n",
      "what's the weather in New York?\n",
      "================================== Ai Message ==================================\n",
      "Tool Calls:\n",
      "  get_temperature (tool_call_id_1)\n",
      " Call ID: tool_call_id_1\n",
      "  Args:\n",
      "    city: New York\n",
      "================================= Tool Message =================================\n",
      "Name: get_temperature\n",
      "\n",
      "Current temperature in New York is 80 degrees.\n",
      "================================== Ai Message ==================================\n",
      "\n",
      "FINAL ANSWER: The current temperature in New York is 80 degrees.\n"
     ]
    }
   ],
   "source": [
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"what's the weather in New York?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    print(chunk[\"messages\"][-1].pretty_repr())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
