{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent to take follow up actions after analysis issue fix\n",
    "\n",
    "This is an agent that uses \"Additional Information\" from fix generation agent to make further changes.\n",
    "\n",
    "For faster prototyping, we use LangGraph for implementing this.\n",
    "\n",
    "We create a simple network of agents - FixGenerationAgent, FileOperationsAgent. \n",
    "\n",
    "The _FixGenerationAgent_ is the same as what we use today to fix analyzer issues. _FileOperationsAgent_ is a new agent we introduce that takes follow up actions. The follow up actions include updating another file, removing a file, or creating a new file. For each operation, we have a tool defined.\n",
    "\n",
    "![Diagram](./screenshots/Tool.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Generation Agent\n",
    "\n",
    "This is same as the existing agent we use to fix analysis issues.\n",
    "\n",
    "We are using a few hardcoded examples of analysis issues to generate fixes.\n",
    "\n",
    "Before proceeding, make sure you are using Kai venv to run cells in this notebook.\n",
    "\n",
    "We need to install `langgraph` module, run following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL CONTAINS SOME COMMON FUNCTIONS WE WILL USE, RUN THIS CELL BEFORE MOVING FORWARD\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_llm_response(message: str) -> tuple[str, str, str]:\n",
    "    lines_of_output = message.splitlines()\n",
    "    in_source_file = False\n",
    "    in_reasoning = False\n",
    "    in_additional_details = False\n",
    "    source_file = \"\"\n",
    "    reasoning = \"\"\n",
    "    additional_details = \"\"\n",
    "    for line in lines_of_output:\n",
    "        # trunk-ignore(cspell/error)\n",
    "        if re.match(r\"(?:##|\\*\\*)\\s+[Rr]easoning\", line.strip()):\n",
    "            in_reasoning = True\n",
    "            in_source_file = False\n",
    "            in_additional_details = False\n",
    "            continue\n",
    "        # trunk-ignore(cspell/error)\n",
    "        if re.match(r\"(?:##|\\*\\*)\\s+[Uu]pdated.*[Ff]ile\", line.strip()):\n",
    "            in_source_file = True\n",
    "            in_reasoning = False\n",
    "            in_additional_details = False\n",
    "            continue\n",
    "        # trunk-ignore(cspell/error)\n",
    "        if re.match(r\"(?:##|\\*\\*)\\s+[Aa]dditional\\s+[Ii]nformation\", line.strip()):\n",
    "            in_reasoning = False\n",
    "            in_source_file = False\n",
    "            in_additional_details = True\n",
    "            continue\n",
    "        if in_source_file:\n",
    "            if re.match(r\"```(?:\\w*)\", line):\n",
    "                continue\n",
    "            source_file = \"\\n\".join([source_file, line])\n",
    "        if in_reasoning:\n",
    "            reasoning = \"\\n\".join([reasoning, line])\n",
    "        if in_additional_details:\n",
    "            additional_details = \"\\n\".join([additional_details, line])\n",
    "    return source_file, reasoning, additional_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the analysis fix agent and generate a few example fixes to be used with file operation agents. \n",
    "\n",
    "The example issues are taken from Coolstore application analysis and can be found in [example_prompts](./example_prompts/) directory.\n",
    "\n",
    "Running the following cell will generate analysis fixes for all examples and store them in variables for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# fix generation agent\n",
    "fix_gen_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    name=\"fix_gen_agent\",\n",
    "    prompt=\"You are an experienced Java developer, who specializes in migrating code from Java EE to Quarkus\",\n",
    "    tools=[],\n",
    ")\n",
    "\n",
    "raw_response_ex1 = fix_gen_agent.invoke({\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=Path(\"example_prompts\", \"inventory_notification_java\", \"jms-to-reactive-quarkus-00050\").read_text()),\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use following additional info for Example-1:\n",
      "\n",
      "\n",
      "- Ensure your `pom.xml` includes the necessary Quarkus SmallRye Reactive Messaging dependencies. For example:\n",
      "  ```xml\n",
      "  <dependency>\n",
      "    <groupId>io.quarkus</groupId>\n",
      "    <artifactId>quarkus-smallrye-reactive-messaging</artifactId>\n",
      "  </dependency>\n",
      "  ```\n",
      "- Configure the messaging channel in `application.properties` to connect to your message broker.\n",
      "- This refactor assumes that somewhere in the application's configuration, the channel with the name `\"orders\"` is set up.\n",
      "- Further migration steps might include migrating other Java EE specific annotations and configurations to their Quarkus equivalents.\n"
     ]
    }
   ],
   "source": [
    "_, _, additional_info_ex1 = parse_llm_response(raw_response_ex1[\"messages\"][-1].content)\n",
    "print(\"We will use following additional info for Example-1:\")\n",
    "print(additional_info_ex1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Operations Agent\n",
    "\n",
    "This is the agent that will take \"Additional Information\" generated by previous agent as input and take actions if there is anything important in additional information. \n",
    "\n",
    "The actions include:\n",
    " * updating an existing file (which may not be same as the original file we fixed)\n",
    " * deleting a file\n",
    " * creating a new file\n",
    "\n",
    "The agent will use following tools to take the above options:\n",
    " * find: Finds relevant files in the project\n",
    " * read: Reads a file in the project\n",
    " * write: Writes content to a file in the project\n",
    " * rm: Removes a file from the project\n",
    "\n",
    "In the following cell, we define these tools and the agent.\n",
    "\n",
    "The [project](./project/) directory is the base of the project and will be used by the agent to perform file operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bVkVc3DVzKnj5qYoyCyNIgJA', 'function': {'arguments': '{\"file_name_pattern\":\"pom.xml\"}', 'name': 'find'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 496, 'total_tokens': 513, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-36f55a6f-f9f0-49ff-983a-f37bea323d1e-0', tool_calls=[{'name': 'find', 'args': {'file_name_pattern': 'pom.xml'}, 'id': 'call_bVkVc3DVzKnj5qYoyCyNIgJA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 496, 'output_tokens': 17, 'total_tokens': 513, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml', name='find', id='c7390540-d374-4fe3-83dc-e3269c351d6f', tool_call_id='call_bVkVc3DVzKnj5qYoyCyNIgJA')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fEy7VGDudxfJIlFApoMNbpph', 'function': {'arguments': '{\"file_name\":\"/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml\"}', 'name': 'read'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 539, 'total_tokens': 573, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a22d4dc5-5835-4e5b-b7ce-90d0107bc5aa-0', tool_calls=[{'name': 'read', 'args': {'file_name': '/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml'}, 'id': 'call_fEy7VGDudxfJIlFApoMNbpph', 'type': 'tool_call'}], usage_metadata={'input_tokens': 539, 'output_tokens': 34, 'total_tokens': 573, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='Here are the file contents:\\n```<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<project \\n    xmlns=\"http://maven.apache.org/POM/4.0.0\" \\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\\n    <modelVersion>4.0.0</modelVersion>\\n    <groupId>com.redhat.coolstore</groupId>\\n    <artifactId>monolith</artifactId>\\n    <version>1.0.0-SNAPSHOT</version>\\n    <packaging>war</packaging>\\n    <name>coolstore-monolith</name>\\n    <properties>\\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\\n        <maven.build.timestamp.format>yyyyMMdd\\'T\\'HHmmss</maven.build.timestamp.format>\\n        <project.encoding>UTF-8</project.encoding>\\n        <maven.test.skip>true</maven.test.skip>\\n    </properties>\\n    <dependencies>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-web-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.jms</groupId>\\n            <artifactId>jboss-jms-api_2.0_spec</artifactId>\\n            <version>2.0.0.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.flywaydb</groupId>\\n            <artifactId>flyway-core</artifactId>\\n            <version>4.1.2</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.rmi</groupId>\\n            <artifactId>jboss-rmi-api_1.0_spec</artifactId>\\n            <version>1.0.2.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-resteasy</artifactId>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-arc</artifactId>\\n        </dependency>\\n    </dependencies>\\n    <build>\\n        <finalName>ROOT</finalName>\\n        <plugins>\\n            <plugin>\\n                <artifactId>maven-compiler-plugin</artifactId>\\n                <version>3.0</version>\\n                <configuration>\\n                    <encoding>${project.encoding}</encoding>\\n                    <source>1.8</source>\\n                    <target>1.8</target>\\n                </configuration>\\n            </plugin>\\n            <plugin>\\n                <groupId>org.apache.maven.plugins</groupId>\\n                <artifactId>maven-war-plugin</artifactId>\\n                <version>3.2.0</version>\\n            </plugin>\\n        </plugins>\\n    </build>\\n    <profiles>\\n<!-- TODO: Add OpenShift profile here -->\\n    </profiles>\\n</project>```', name='read', id='bab9c46c-2089-41c5-93d9-18010dabd202', tool_call_id='call_fEy7VGDudxfJIlFApoMNbpph')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_nUOUClhUGoKfMXER8fECVy2I', 'function': {'arguments': '{\"file_name\": \"/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml\", \"content\": \"<?xml version=\\\\\"1.0\\\\\" encoding=\\\\\"UTF-8\\\\\"?>\\\\n<project \\\\n    xmlns=\\\\\"http://maven.apache.org/POM/4.0.0\\\\\" \\\\n    xmlns:xsi=\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\" xsi:schemaLocation=\\\\\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\\\\\">\\\\n    <modelVersion>4.0.0</modelVersion>\\\\n    <groupId>com.redhat.coolstore</groupId>\\\\n    <artifactId>monolith</artifactId>\\\\n    <version>1.0.0-SNAPSHOT</version>\\\\n    <packaging>war</packaging>\\\\n    <name>coolstore-monolith</name>\\\\n    <properties>\\\\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\\\\n        <maven.build.timestamp.format>yyyyMMdd\\'T\\'HHmmss</maven.build.timestamp.format>\\\\n        <project.encoding>UTF-8</project.encoding>\\\\n        <maven.test.skip>true</maven.test.skip>\\\\n    </properties>\\\\n    <dependencies>\\\\n        <dependency>\\\\n            <groupId>javax</groupId>\\\\n            <artifactId>javaee-web-api</artifactId>\\\\n            <version>7.0</version>\\\\n            <scope>provided</scope>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>javax</groupId>\\\\n            <artifactId>javaee-api</artifactId>\\\\n            <version>7.0</version>\\\\n            <scope>provided</scope>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>org.jboss.spec.javax.jms</groupId>\\\\n            <artifactId>jboss-jms-api_2.0_spec</artifactId>\\\\n            <version>2.0.0.Final</version>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>org.flywaydb</groupId>\\\\n            <artifactId>flyway-core</artifactId>\\\\n            <version>4.1.2</version>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>org.jboss.spec.javax.rmi</groupId>\\\\n            <artifactId>jboss-rmi-api_1.0_spec</artifactId>\\\\n            <version>1.0.2.Final</version>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>io.quarkus</groupId>\\\\n            <artifactId>quarkus-resteasy</artifactId>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>io.quarkus</groupId>\\\\n            <artifactId>quarkus-arc</artifactId>\\\\n        </dependency>\\\\n        <dependency>\\\\n            <groupId>io.quarkus</groupId>\\\\n            <artifactId>quarkus-smallrye-reactive-messaging</artifactId>\\\\n        </dependency>\\\\n    </dependencies>\\\\n    <build>\\\\n        <finalName>ROOT</finalName>\\\\n        <plugins>\\\\n            <plugin>\\\\n                <artifactId>maven-compiler-plugin</artifactId>\\\\n                <version>3.0</version>\\\\n                <configuration>\\\\n                    <encoding>${project.encoding}</encoding>\\\\n                    <source>1.8</source>\\\\n                    <target>1.8</target>\\\\n                </configuration>\\\\n            </plugin>\\\\n            <plugin>\\\\n                <groupId>org.apache.maven.plugins</groupId>\\\\n                <artifactId>maven-war-plugin</artifactId>\\\\n                <version>3.2.0</version>\\\\n            </plugin>\\\\n        </plugins>\\\\n    </build>\\\\n    <profiles>\\\\n<!-- TODO: Add OpenShift profile here -->\\\\n    </profiles>\\\\n</project>\"}', 'name': 'write'}, 'type': 'function'}, {'id': 'call_wsDssbdBjt7e7ftsB6k4ApzV', 'function': {'arguments': '{\"file_name_pattern\": \"application.properties\"}', 'name': 'find'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 919, 'prompt_tokens': 1316, 'total_tokens': 2235, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1024}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-bccec0a7-b210-46a0-b537-1b42c2b48e84-0', tool_calls=[{'name': 'write', 'args': {'file_name': '/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml', 'content': '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<project \\n    xmlns=\"http://maven.apache.org/POM/4.0.0\" \\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\\n    <modelVersion>4.0.0</modelVersion>\\n    <groupId>com.redhat.coolstore</groupId>\\n    <artifactId>monolith</artifactId>\\n    <version>1.0.0-SNAPSHOT</version>\\n    <packaging>war</packaging>\\n    <name>coolstore-monolith</name>\\n    <properties>\\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\\n        <maven.build.timestamp.format>yyyyMMdd\\'T\\'HHmmss</maven.build.timestamp.format>\\n        <project.encoding>UTF-8</project.encoding>\\n        <maven.test.skip>true</maven.test.skip>\\n    </properties>\\n    <dependencies>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-web-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.jms</groupId>\\n            <artifactId>jboss-jms-api_2.0_spec</artifactId>\\n            <version>2.0.0.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.flywaydb</groupId>\\n            <artifactId>flyway-core</artifactId>\\n            <version>4.1.2</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.rmi</groupId>\\n            <artifactId>jboss-rmi-api_1.0_spec</artifactId>\\n            <version>1.0.2.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-resteasy</artifactId>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-arc</artifactId>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-smallrye-reactive-messaging</artifactId>\\n        </dependency>\\n    </dependencies>\\n    <build>\\n        <finalName>ROOT</finalName>\\n        <plugins>\\n            <plugin>\\n                <artifactId>maven-compiler-plugin</artifactId>\\n                <version>3.0</version>\\n                <configuration>\\n                    <encoding>${project.encoding}</encoding>\\n                    <source>1.8</source>\\n                    <target>1.8</target>\\n                </configuration>\\n            </plugin>\\n            <plugin>\\n                <groupId>org.apache.maven.plugins</groupId>\\n                <artifactId>maven-war-plugin</artifactId>\\n                <version>3.2.0</version>\\n            </plugin>\\n        </plugins>\\n    </build>\\n    <profiles>\\n<!-- TODO: Add OpenShift profile here -->\\n    </profiles>\\n</project>'}, 'id': 'call_nUOUClhUGoKfMXER8fECVy2I', 'type': 'tool_call'}, {'name': 'find', 'args': {'file_name_pattern': 'application.properties'}, 'id': 'call_wsDssbdBjt7e7ftsB6k4ApzV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1316, 'output_tokens': 919, 'total_tokens': 2235, 'input_token_details': {'audio': 0, 'cache_read': 1024}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='Successfully wrote contents to file /Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml', name='write', id='4852602e-01ff-4932-b8b8-fd0726bd634a', tool_call_id='call_nUOUClhUGoKfMXER8fECVy2I'), ToolMessage(content='No files found matching pattern application.properties', name='find', id='decac8bc-66d4-4cd6-a085-d7e45d9f2171', tool_call_id='call_wsDssbdBjt7e7ftsB6k4ApzV')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_zHU1cLukmXKd9pNPEDRfpXGG', 'function': {'arguments': '{\"file_name\":\"/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/src/main/resources/application.properties\",\"content\":\"# Configure the \\\\\"orders\\\\\" channel to connect to the message broker\\\\nmp.messaging.incoming.orders.connector=smallrye-kafka\\\\nmp.messaging.incoming.orders.topic=orders\\\\nmp.messaging.incoming.orders.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer\\\\nmp.messaging.incoming.orders.bootstrap.servers=localhost:9092\"}', 'name': 'write'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 105, 'prompt_tokens': 2280, 'total_tokens': 2385, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2176}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8e8e074d-b718-4535-938f-d3876927241c-0', tool_calls=[{'name': 'write', 'args': {'file_name': '/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/src/main/resources/application.properties', 'content': '# Configure the \"orders\" channel to connect to the message broker\\nmp.messaging.incoming.orders.connector=smallrye-kafka\\nmp.messaging.incoming.orders.topic=orders\\nmp.messaging.incoming.orders.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer\\nmp.messaging.incoming.orders.bootstrap.servers=localhost:9092'}, 'id': 'call_zHU1cLukmXKd9pNPEDRfpXGG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2280, 'output_tokens': 105, 'total_tokens': 2385, 'input_token_details': {'audio': 0, 'cache_read': 2176}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='Successfully wrote contents to file /Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/src/main/resources/application.properties', name='write', id='217d33de-8c78-4406-a167-1f7bfdccece3', tool_call_id='call_zHU1cLukmXKd9pNPEDRfpXGG')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='I have successfully updated the `pom.xml` file to include the necessary Quarkus SmallRye Reactive Messaging dependency. Additionally, I\\'ve created the `application.properties` file and configured it to connect the `\"orders\"` channel to your message broker using SmallRye Kafka. If there are any additional migrations required, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 2418, 'total_tokens': 2487, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2304}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None}, id='run-96e9e87a-4e4e-4e49-b8b1-b99e8a3db24e-0', usage_metadata={'input_tokens': 2418, 'output_tokens': 69, 'total_tokens': 2487, 'input_token_details': {'audio': 0, 'cache_read': 2304}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated\n",
    "\n",
    "@tool\n",
    "def find(file_name_pattern: Annotated[str, \"Glob pattern to match file names\"]) -> Annotated[str, \"Absolute paths of the files found separated by newlines\"]:\n",
    "    \"\"\"Given a glob pattern, searches for files matching the pattern in project and returns absolute paths of the files\n",
    "\n",
    "    Returns:\n",
    "        str: Newline separated list of filepaths\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matching_files = glob.glob(\"./project/\" + file_name_pattern, recursive=True)\n",
    "    except Exception as e:\n",
    "        return f\"Failed to search for files because of error - {e}\"\n",
    "    absolute_paths = [os.path.abspath(file) for file in matching_files]\n",
    "    if not absolute_paths:\n",
    "        return f\"No files found matching pattern {file_name_pattern}\"\n",
    "    return \"\\n\".join(absolute_paths)\n",
    "\n",
    "@tool\n",
    "def read(file_name: Annotated[str, \"Absolute path to the file to read\"]):\n",
    "    \"\"\"Given an absolute path to a file, reads the file and returns content\"\"\"\n",
    "    if os.path.exists(file_name):\n",
    "        contents = \"\"\n",
    "        with open(file_name, \"r\") as f:\n",
    "            contents = f.read()\n",
    "        return f\"Here are the file contents:\\n```{contents}```\"\n",
    "    return f\"File {file_name} does not exist\"\n",
    "\n",
    "@tool\n",
    "def write(file_name: Annotated[str, \"Absolute path to the file\"], content: Annotated[str, \"Content to write to the file\"]):\n",
    "    \"\"\"Given an absolute path to a file and the content, writes content to the file. If the file doesn't exist, creates a new file.\n",
    "    If the directories dont exist, creates all parent directories.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "        with open(file_name, \"w+\") as f:\n",
    "            f.write(content)\n",
    "        return f\"Successfully wrote contents to file {file_name}\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to write to file with error {e}\"\n",
    "\n",
    "@tool\n",
    "def rm(file: Annotated[str, \"Full path of the file to remove\"]):\n",
    "    \"\"\"Removes file\"\"\"\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        return \"Removed the file\"\n",
    "    return f\"File {file} does not exist\"\n",
    "\n",
    "file_ops_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[find, read, write, rm],\n",
    "    prompt=\"\"\"You are an expert Java developer. You are asked to make changes in a Java project.\n",
    "You can either update an existing file, delete a file, or create a new file with relevant content.\n",
    "To update or delete an existing file, search for the file to update using a glob pattern, and determine which file to update from the files found.\n",
    "To update an existing file, make sure you read the file to get existing contents, and then write to the file updated content.\n",
    "If a file doesn't exist and needs to be created, create that file.\n",
    "Always use absolute file paths to make changes to files. You are given tools to perform file operations. Use the tools, and make the changes needed.\n",
    "Use your best judgement to solve the issues described.\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "for state in file_ops_agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=additional_info_ex1)]},\n",
    "    stream_mode=[\"updates\"]\n",
    "):\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "In the above output, you can see that the model searched for `pom.xml` file and added the dependency. \n",
    "\n",
    "It also searched for `application.properties` file but it wasn't found, so it created a new file at path `src/main/resources` which is the correct path for Quarkus applications. \n",
    "\n",
    "This proves the possibility of updating another file from the project, AND creating a new file.\n",
    "\n",
    "I have attached screenshots of the results from my environment below.\n",
    "\n",
    "![pom_xml_update](./screenshots/pom_xml_update.png)\n",
    "\n",
    "![application_properties_creation](./screenshots/application_properties_creation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Removal Example\n",
    "\n",
    "Lets take a look at another example where we have to remove a `web.xml` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BErckULSix64WOTimSabFREt', 'function': {'arguments': '{\"file_name_pattern\":\"**/beans.xml\"}', 'name': 'find'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 486, 'total_tokens': 505, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e6e94688-0c50-4a39-b16d-ff9e3cb17734-0', tool_calls=[{'name': 'find', 'args': {'file_name_pattern': '**/beans.xml'}, 'id': 'call_BErckULSix64WOTimSabFREt', 'type': 'tool_call'}], usage_metadata={'input_tokens': 486, 'output_tokens': 19, 'total_tokens': 505, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/beans.xml', name='find', id='f190cbae-6ddc-41a9-a2ab-afd992938b0b', tool_call_id='call_BErckULSix64WOTimSabFREt')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fhQHwDs0ZhAW9zGLUSfZZ8Wm', 'function': {'arguments': '{\"file\":\"/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/beans.xml\"}', 'name': 'rm'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 531, 'total_tokens': 564, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-34a04dd6-b1d1-4884-a318-587bdaded097-0', tool_calls=[{'name': 'rm', 'args': {'file': '/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/beans.xml'}, 'id': 'call_fhQHwDs0ZhAW9zGLUSfZZ8Wm', 'type': 'tool_call'}], usage_metadata={'input_tokens': 531, 'output_tokens': 33, 'total_tokens': 564, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='Removed the file', name='rm', id='4f8bef7a-7ff1-4e97-aacd-40e8918d896d', tool_call_id='call_fhQHwDs0ZhAW9zGLUSfZZ8Wm')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gDENcPLEM8eJMewCkxPACMeA', 'function': {'arguments': '{\"file_name_pattern\":\"**/pom.xml\"}', 'name': 'find'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 573, 'total_tokens': 592, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-27b77fa0-2213-405d-861e-7bcd531e5eba-0', tool_calls=[{'name': 'find', 'args': {'file_name_pattern': '**/pom.xml'}, 'id': 'call_gDENcPLEM8eJMewCkxPACMeA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 573, 'output_tokens': 19, 'total_tokens': 592, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml', name='find', id='12f5f85f-437c-4ff1-832c-0c671efbf8a8', tool_call_id='call_gDENcPLEM8eJMewCkxPACMeA')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hStsAd7uxMxG7kHaaH2S9YcM', 'function': {'arguments': '{\"file_name\":\"/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml\"}', 'name': 'read'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 618, 'total_tokens': 652, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e22505ba-69d0-4e9d-9ecb-7e041d36f2dd-0', tool_calls=[{'name': 'read', 'args': {'file_name': '/Users/pgaikwad/Projects/kai/notebooks/followup_agent/project/pom.xml'}, 'id': 'call_hStsAd7uxMxG7kHaaH2S9YcM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 618, 'output_tokens': 34, 'total_tokens': 652, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n",
      "('updates', {'tools': {'messages': [ToolMessage(content='Here are the file contents:\\n```<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<project \\n    xmlns=\"http://maven.apache.org/POM/4.0.0\" \\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\\n    <modelVersion>4.0.0</modelVersion>\\n    <groupId>com.redhat.coolstore</groupId>\\n    <artifactId>monolith</artifactId>\\n    <version>1.0.0-SNAPSHOT</version>\\n    <packaging>war</packaging>\\n    <name>coolstore-monolith</name>\\n    <properties>\\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\\n        <maven.build.timestamp.format>yyyyMMdd\\'T\\'HHmmss</maven.build.timestamp.format>\\n        <project.encoding>UTF-8</project.encoding>\\n        <maven.test.skip>true</maven.test.skip>\\n    </properties>\\n    <dependencies>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-web-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>javax</groupId>\\n            <artifactId>javaee-api</artifactId>\\n            <version>7.0</version>\\n            <scope>provided</scope>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.jms</groupId>\\n            <artifactId>jboss-jms-api_2.0_spec</artifactId>\\n            <version>2.0.0.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.flywaydb</groupId>\\n            <artifactId>flyway-core</artifactId>\\n            <version>4.1.2</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>org.jboss.spec.javax.rmi</groupId>\\n            <artifactId>jboss-rmi-api_1.0_spec</artifactId>\\n            <version>1.0.2.Final</version>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-resteasy</artifactId>\\n        </dependency>\\n        <dependency>\\n            <groupId>io.quarkus</groupId>\\n            <artifactId>quarkus-arc</artifactId>\\n        </dependency>\\n    </dependencies>\\n    <build>\\n        <finalName>ROOT</finalName>\\n        <plugins>\\n            <plugin>\\n                <artifactId>maven-compiler-plugin</artifactId>\\n                <version>3.0</version>\\n                <configuration>\\n                    <encoding>${project.encoding}</encoding>\\n                    <source>1.8</source>\\n                    <target>1.8</target>\\n                </configuration>\\n            </plugin>\\n            <plugin>\\n                <groupId>org.apache.maven.plugins</groupId>\\n                <artifactId>maven-war-plugin</artifactId>\\n                <version>3.2.0</version>\\n            </plugin>\\n        </plugins>\\n    </build>\\n    <profiles>\\n<!-- TODO: Add OpenShift profile here -->\\n    </profiles>\\n</project>```', name='read', id='bec5ee37-5afe-4480-9514-197deda81ef0', tool_call_id='call_hStsAd7uxMxG7kHaaH2S9YcM')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content=\"The `pom.xml` file already includes the necessary CDI dependencies for Quarkus support, namely `quarkus-resteasy` and `quarkus-arc`. \\n\\nHere's a summary of the changes made and the current status:\\n- **Removed `beans.xml`:** The `beans.xml` file was successfully removed.\\n- **Verified Dependencies:** The `pom.xml` file contains the `quarkus-resteasy` and `quarkus-arc` extensions, ensuring CDI support in the application.\\n\\nNext, ensure that the application is tested properly to verify that CDI is functioning as expected without the `beans.xml` file. Additionally, refer to the [Quarkus CDI Guide](https://quarkus.io/guides/cdi) for more details on handling CDI with Quarkus.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 166, 'prompt_tokens': 1395, 'total_tokens': 1561, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None}, id='run-3c8f1d8e-d7c5-4925-a4a9-80a2dc3bbfe7-0', usage_metadata={'input_tokens': 1395, 'output_tokens': 166, 'total_tokens': 1561, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n"
     ]
    }
   ],
   "source": [
    "additional_info_ex2 = \"\"\"- **Documentation Reference:** For more details on how Quarkus handles CDI, refer to the [Quarkus CDI Guide](https://quarkus.io/guides/cdi).\n",
    "- **Testing:** After removing `beans.xml`, ensure that the application is tested to verify that CDI is functioning as expected without the file.\n",
    "- **Dependencies:** Double-check the `pom.xml` to ensure all necessary CDI dependencies are included for Quarkus. This typically involves ensuring that the `quarkus-resteasy` or `quarkus-arc` extensions are present, as they provide CDI support.\"\"\"\n",
    "\n",
    "for state in file_ops_agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=additional_info_ex2)]},\n",
    "    stream_mode=[\"updates\"]\n",
    "):\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We can see that the `beans.xml` file is removed by the agent. See screenshot below:\n",
    "\n",
    "![beans_removal](./screenshots/beans_xml_removal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating tool usage with different providers via Model Provider\n",
    "\n",
    "This section validates that we are able to use tools with different Model Providers we support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "\n",
    "@tool\n",
    "def get_temperature(city: Annotated[str, \"Name of the city\"]):\n",
    "    \"\"\"Returns current temperature in given city\"\"\"\n",
    "    return f\"Current temperature in {city} is 80 degrees.\"\n",
    "\n",
    "def validate(model: LanguageModelLike, **kwargs):\n",
    "    agent = create_react_agent(\n",
    "        model=model,\n",
    "        tools=[get_temperature],\n",
    "        prompt=\"Help the user with their queries, use the tools at your disposal.\",\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    for r in agent.stream({\"messages\": [(\"user\", \"What is the current temperature in New York?\")]}):\n",
    "        print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on which model you test this with, you need to set up your API keys for the model before running the \"validation\" cell. Every cell has a comment at top about the environment variable expected.\n",
    "\n",
    "You will set the keys in `.env` file at the project root and run the following cell for changes to take effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "|   Kai Model Provider   |      Model       |  Works?  |\n",
    "| ---------------------- | ---------------- | -------- |\n",
    "| ChatOpenAI             | gpt-3.5-turbo    |  &check; |\n",
    "| ChatOpenAI (RH Maas)   | granite-8b       |  &check; |\n",
    "| ChatOpenAI (RH Maas)   | llama-7b         |  &check; |\n",
    "| ChatBedrock            | llama-70b-v1     |  &cross; |\n",
    "| ChatBedrock            | llama-70b-v2     |  &cross; |\n",
    "| ChatBedrock            | claude-3-sonnet  |  &check; |\n",
    "| ChatGoogleGenAI        | gemini-2.0-flash |  &check; |\n",
    "| ChatDeepSeek           | deepseek-chat    |  &check; |\n",
    "\n",
    "Following model providers are not tested yet:\n",
    "\n",
    "* ChatOllama\n",
    "* ChatAzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-93d38e3ef7764368aeab44edfa14db42', 'function': {'arguments': '{\"city\": \"New York\"}', 'name': 'get_temperature'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 140, 'total_tokens': 165, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'granite-3-8b-instruct', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-97df9c64-fad3-4df2-b314-76b4fc50324e-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': 'chatcmpl-tool-93d38e3ef7764368aeab44edfa14db42', 'type': 'tool_call'}], usage_metadata={'input_tokens': 140, 'output_tokens': 25, 'total_tokens': 165, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='92aee6a7-fc0c-4137-991f-dfbdbd915f92', tool_call_id='chatcmpl-tool-93d38e3ef7764368aeab44edfa14db42')]}}\n",
      "{'agent': {'messages': [AIMessage(content='The current temperature in New York is 80 degrees.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 161, 'total_tokens': 174, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'granite-3-8b-instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-efec3793-40ed-4125-96ea-8dfdb247961a-0', usage_metadata={'input_tokens': 161, 'output_tokens': 13, 'total_tokens': 174, 'input_token_details': {}, 'output_token_details': {}})]}}\n"
     ]
    }
   ],
   "source": [
    "## Test with granite-8b on RH maas via ChatOpenAI\n",
    "## Env vars needed:\n",
    "## PARASOL_GRANITE_KEY - api key\n",
    "## PARASON_GRANITE_API - base url (usually ends with /v1)\n",
    "\n",
    "from kai.llm_interfacing.model_provider import ChatOpenAI\n",
    "\n",
    "validate(ChatOpenAI(\n",
    "    api_key=os.environ[\"PARASOL_GRANITE_KEY\"],\n",
    "    base_url=os.environ[\"PARASOL_GRANITE_API\"],\n",
    "    model_name=\"granite-3-8b-instruct\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-671b7256d3e94bed833385429a6d5168', 'function': {'arguments': '{\"city\": \"New York\"}', 'name': 'get_temperature'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 206, 'total_tokens': 224, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-fe619e78-3d5f-4814-8a78-a4f9b24d9b7d-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': 'chatcmpl-tool-671b7256d3e94bed833385429a6d5168', 'type': 'tool_call'}], usage_metadata={'input_tokens': 206, 'output_tokens': 18, 'total_tokens': 224, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='ba529951-2d5f-4a2c-82ef-1dcf4bbac5fd', tool_call_id='chatcmpl-tool-671b7256d3e94bed833385429a6d5168')]}}\n",
      "{'agent': {'messages': [AIMessage(content=\"I used the hypothetical output of the function to create a sample response. However, in a real scenario, the function would return the actual temperature value as per the actual output of the 'get_temperature' function.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 249, 'total_tokens': 292, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/Llama-3.1-8B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-496d77f3-4914-46a8-90ac-225c3c7b2011-0', usage_metadata={'input_tokens': 249, 'output_tokens': 43, 'total_tokens': 292, 'input_token_details': {}, 'output_token_details': {}})]}}\n"
     ]
    }
   ],
   "source": [
    "validate(ChatOpenAI(\n",
    "    api_key=os.environ[\"PARASOL_LLAMA_KEY\"],\n",
    "    base_url=os.environ[\"PARASOL_LLAMA_API\"],\n",
    "    model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hyQWUzmMBoWcy7lgjdtKMqKK', 'function': {'arguments': '{\"city\":\"New York\"}', 'name': 'get_temperature'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 75, 'total_tokens': 91, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ef88bd74-8e49-47b8-a583-ad33145a439f-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': 'call_hyQWUzmMBoWcy7lgjdtKMqKK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 75, 'output_tokens': 16, 'total_tokens': 91, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='7339a847-6267-4964-8f81-0c3ca9a3c4e0', tool_call_id='call_hyQWUzmMBoWcy7lgjdtKMqKK')]}}\n",
      "{'agent': {'messages': [AIMessage(content='The current temperature in New York is 80 degrees.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 108, 'total_tokens': 121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-176cd009-bd24-40c6-be5c-dd29a95bfd59-0', usage_metadata={'input_tokens': 108, 'output_tokens': 13, 'total_tokens': 121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "## Test with gpt-3.5-turbo via ChatOpenAI\n",
    "## Env vars needed:\n",
    "## OPENAI_API_KEY - api key\n",
    "\n",
    "validate(ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_temperature', 'arguments': '{\"city\": \"New York\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-0345ec89-e933-4a1a-9645-ca54d4a3d3b6-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': '84239db4-b642-4c92-9a83-ec759f341dff', 'type': 'tool_call'}], usage_metadata={'input_tokens': 38, 'output_tokens': 6, 'total_tokens': 44, 'input_token_details': {'cache_read': 0}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='5ed17fd0-c2b7-4f5a-9449-0c1287060c19', tool_call_id='84239db4-b642-4c92-9a83-ec759f341dff')]}}\n",
      "{'agent': {'messages': [AIMessage(content='The current temperature in New York is 80 degrees.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-9e6ccb8d-9110-4cee-94db-a6085ffffed8-0', usage_metadata={'input_tokens': 59, 'output_tokens': 13, 'total_tokens': 72, 'input_token_details': {'cache_read': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "## Test with gemini-2.0-flash via GoogleGenAI\n",
    "## Env vars needed:\n",
    "## GEMINI_API_KEY - api key\n",
    "\n",
    "from kai.llm_interfacing.model_provider import ChatGoogleGenerativeAI\n",
    "\n",
    "validate(ChatGoogleGenerativeAI(\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    model=\"gemini-2.0-flash\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"I'm just an AI, I don't have access to real-time weather data. However, I can suggest some ways for you to find out the current temperature in New York:\\n\\n1. Check online weather websites: You can check websites like AccuWeather, Weather.com, or the National Weather Service (NWS) for the current temperature in New York.\\n2. Use a weather app: You can download a weather app on your smartphone, such as Dark Sky or Weather Underground, which can provide you with real-time weather information, including the current temperature.\\n3. Check social media: Many weather organizations and meteorologists share current weather conditions, including temperature, on social media platforms like Twitter and Facebook.\\n4. Tune into local news: You can watch local news or listen to local radio stations to get the current temperature and weather forecast for New York.\\n\\nPlease note that the temperature can change rapidly, so it's always a good idea to check multiple sources for the most up-to-date information.\", additional_kwargs={'usage': {'prompt_tokens': 39, 'completion_tokens': 200, 'total_tokens': 239}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-1-70b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 39, 'completion_tokens': 200, 'total_tokens': 239}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-1-70b-instruct-v1:0'}, id='run-e5b9bdad-42ca-4706-87d3-45b911b4d674-0', usage_metadata={'input_tokens': 39, 'output_tokens': 200, 'total_tokens': 239})]}}\n"
     ]
    }
   ],
   "source": [
    "## Test with llama-70b via Bedrock\n",
    "## Env vars needed:\n",
    "## AWS_ACCESS_KEY_ID\n",
    "## AWS_SECRET_ACCESS_KEY\n",
    "\n",
    "from kai.llm_interfacing.model_provider import ChatBedrock\n",
    "\n",
    "validate(ChatBedrock(\n",
    "    model=\"us.meta.llama3-1-70b-instruct-v1:0\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"I'm just an AI, I don't have real-time access to current weather conditions. However, I can suggest some ways for you to find out the current temperature in New York.\\n\\nYou can check the current weather forecast for New York on websites like:\\n\\n* National Weather Service (NWS) - [www.weather.gov](http://www.weather.gov)\\n* AccuWeather - [www.accuweather.com](http://www.accuweather.com)\\n* Weather.com - [www.weather.com](http://www.weather.com)\\n* Google Maps - [maps.google.com](http://maps.google.com) (look for the weather icon)\\n\\nYou can also check your local news or weather app on your smartphone for the current temperature in New York.\\n\\nIf you're looking for a more specific answer, I can try to help you with that. What city in New York are you looking for the temperature in?\", additional_kwargs={'usage': {'prompt_tokens': 39, 'completion_tokens': 182, 'total_tokens': 221}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-2-1b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 39, 'completion_tokens': 182, 'total_tokens': 221}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-2-1b-instruct-v1:0'}, id='run-43bcbfbb-00fb-4616-ab8b-b1aaadee2f32-0', usage_metadata={'input_tokens': 39, 'output_tokens': 182, 'total_tokens': 221})]}}\n"
     ]
    }
   ],
   "source": [
    "validate(ChatBedrock(\n",
    "    model=\"us.meta.llama3-2-1b-instruct-v1:0\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='I\\'m just an AI, I don\\'t have access to real-time information, but I can suggest some ways for you to find the current temperature in New York.\\n\\nYou can check the current temperature in New York by:\\n\\n1. Checking online weather websites such as AccuWeather, Weather.com, or the National Weather Service (NWS) website.\\n2. Using a mobile app like Dark Sky or Weather Underground.\\n3. Searching for \"current temperature in New York\" on a search engine like Google.\\n4. Checking the website of a local news station or newspaper in New York.\\n\\nPlease note that the temperature can vary depending on the location within New York, so it\\'s a good idea to check the temperature for a specific location, such as Manhattan, Brooklyn, or Queens.', additional_kwargs={'usage': {'prompt_tokens': 40, 'completion_tokens': 157, 'total_tokens': 197}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-3-70b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 40, 'completion_tokens': 157, 'total_tokens': 197}, 'stop_reason': 'stop', 'model_id': 'us.meta.llama3-3-70b-instruct-v1:0'}, id='run-3d9cf880-c3f8-4fcf-a3ea-a873adb5d83e-0', usage_metadata={'input_tokens': 40, 'output_tokens': 157, 'total_tokens': 197})]}}\n"
     ]
    }
   ],
   "source": [
    "validate(ChatBedrock(\n",
    "    model=\"us.meta.llama3-3-70b-instruct-v1:0\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'usage': {'prompt_tokens': 253, 'completion_tokens': 54, 'total_tokens': 307}, 'stop_reason': 'tool_use', 'model_id': 'us.anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 253, 'completion_tokens': 54, 'total_tokens': 307}, 'stop_reason': 'tool_use', 'model_id': 'us.anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-ebe41a8a-c51b-4c47-b222-b73af17499b4-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': 'toolu_bdrk_01ACM8hMxuQHJeGnbQLDqqgz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 253, 'output_tokens': 54, 'total_tokens': 307})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='51824bd5-9d8e-4e26-8795-603c48d155c6', tool_call_id='toolu_bdrk_01ACM8hMxuQHJeGnbQLDqqgz')]}}\n",
      "{'agent': {'messages': [AIMessage(content='The current temperature in New York is 80 degrees Fahrenheit.', additional_kwargs={'usage': {'prompt_tokens': 329, 'completion_tokens': 19, 'total_tokens': 348}, 'stop_reason': 'end_turn', 'model_id': 'us.anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 329, 'completion_tokens': 19, 'total_tokens': 348}, 'stop_reason': 'end_turn', 'model_id': 'us.anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-128488f9-58ac-4baf-99a8-41e9b40bf676-0', usage_metadata={'input_tokens': 329, 'output_tokens': 19, 'total_tokens': 348})]}}\n"
     ]
    }
   ],
   "source": [
    "validate(ChatBedrock(\n",
    "    model=\"us.anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_1211c9dd-2ad1-43f3-8696-94c912284b06', 'function': {'arguments': '{\"city\":\"New York\"}', 'name': 'get_temperature'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 129, 'total_tokens': 149, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 128}, 'prompt_cache_hit_tokens': 128, 'prompt_cache_miss_tokens': 1}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3a5770e1b4_prod0225', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06857c74-a5ef-4121-a4a5-590df9397845-0', tool_calls=[{'name': 'get_temperature', 'args': {'city': 'New York'}, 'id': 'call_0_1211c9dd-2ad1-43f3-8696-94c912284b06', 'type': 'tool_call'}], usage_metadata={'input_tokens': 129, 'output_tokens': 20, 'total_tokens': 149, 'input_token_details': {'cache_read': 128}, 'output_token_details': {}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Current temperature in New York is 80 degrees.', name='get_temperature', id='b4290fe8-05a3-474c-b7a9-5d005ec45cda', tool_call_id='call_0_1211c9dd-2ad1-43f3-8696-94c912284b06')]}}\n",
      "{'__interrupt__': ()}\n"
     ]
    }
   ],
   "source": [
    "# Env vars needed:\n",
    "# DEEPSEEK_API_KEY\n",
    "\n",
    "from kai.llm_interfacing.model_provider import ChatDeepSeek\n",
    "\n",
    "validate(model=ChatDeepSeek(\n",
    "    api_key=os.environ[\"DEEPSEEK_API_KEY\"],\n",
    "    model=\"deepseek-chat\",\n",
    "), interrupt_after=[\"tools\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
